{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f438956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import LDAQ #custom version of LDAQ --> should be installed properly via pip\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from data_converter import measurement_dict_to_sep005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d5265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(loaded_data, threshold_V: float = 75e-3, width_s: float = 100e-6, plot: bool = False) -> tuple[npt.ArrayLike, npt.ArrayLike]:\n",
    "    \"\"\"\n",
    "    Threshold the raw sensor data and extract the next `width_s` second from when the threshold is reached.\n",
    "    \"\"\"\n",
    "    time = loaded_data[\"time\"]\n",
    "    data = loaded_data[\"data\"]\n",
    "\n",
    "    width = int(width_s * loaded_data[\"fs\"])\n",
    "\n",
    "    start = np.argmax(np.abs(data) > threshold_V, axis=0)\n",
    "    end = start + width\n",
    "\n",
    "    extracted_data = np.zeros((width, data.shape[1]))\n",
    "    extracted_time = np.zeros((width, data.shape[1]))\n",
    "\n",
    "    for i in range(data.shape[1]):\n",
    "        extracted_data[:, i] = data[start[i]:end[i], i]\n",
    "        extracted_time[:, i] = time[start[i]:end[i]]\n",
    "\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.plot(extracted_time, extracted_data)\n",
    "\n",
    "    return extracted_data, extracted_time\n",
    "\n",
    "\n",
    "def extract_peak_times(extracted_time, extracted_data, smoothing: int = 4, plot: bool = False) -> tuple[npt.ArrayLike, npt.ArrayLike]:\n",
    "    \"\"\"\n",
    "    Extract all peaks from the extracted data. This is done by interpolating a cubic spline through the data taken at every `smoothing` (e.g. 4th) point.\n",
    "    The peaks of this interpolated data and the time at which it occurs is returned\n",
    "    \"\"\"\n",
    "\n",
    "    assert extracted_time.shape == extracted_data.shape, f\"Shapes of time and data don't match\"\n",
    "\n",
    "    peak_times = []\n",
    "    peak_vals = []\n",
    "\n",
    "    for i in range(extracted_data.shape[1]):\n",
    "        t = extracted_time[:, i]\n",
    "        d = extracted_data[:, i]\n",
    "\n",
    "        cs = scipy.interpolate.CubicSpline(t[::smoothing], d[::smoothing])\n",
    "        deriv = cs.derivative()\n",
    "        #deriv_vals = deriv(t)\n",
    "\n",
    "        zero_idx = np.argmax(np.abs(cs(t)))\n",
    "        zero_time = t[zero_idx]\n",
    "\n",
    "        #zero_time = np.min(deriv.roots(extrapolate=False))\n",
    "        #zero_idx = np.argmin(np.abs(t - zero_time))\n",
    "\n",
    "        peak_times.append(zero_time)\n",
    "        peak_vals.append(d[zero_idx])\n",
    "\n",
    "        if plot:\n",
    "            plt.figure()\n",
    "            plt.plot(t, cs(t), t, d, \"--\", zero_time, d[zero_idx], \"x\")\n",
    "\n",
    "    return np.asarray(peak_times), np.asarray(peak_vals)\n",
    "\n",
    "def df_from_folder(data_folder: str, locations: dict, columns: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Iterate through folder and load all measurement files within. Extract the peak times and peak values and append them to a pandas.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    impact_type = data_folder.split(\"/\")[-1]\n",
    "    raw_df_data = []\n",
    "\n",
    "    for file in list(Path(data_folder).glob('*.pkl')):\n",
    "        loaded_data = LDAQ.utils.load_measurement(file.name, directory=data_folder)\n",
    "        loaded_data = measurement_dict_to_sep005(loaded_data)\n",
    "\n",
    "        extracted_data, extracted_time = extract_data(loaded_data)\n",
    "\n",
    "        peak_times, peak_vals = extract_peak_times(extracted_time, extracted_data)\n",
    "        time_offset = peak_times - peak_times[0]\n",
    "        raw_df_data.append([*time_offset, *peak_vals, *locations[impact_type]])\n",
    "\n",
    "    return pd.DataFrame(raw_df_data, columns=columns)\n",
    "\n",
    "locations = {\n",
    "    \"back\": (0, -60),\n",
    "    \"center\": (0, 0),\n",
    "    \"front\": (0, 60)\n",
    "}\n",
    "\n",
    "columns = [\n",
    "    *[f\"S{i+1}\" for i in range(6)],\n",
    "    *[f\"A{i+1}\" for i in range(6)],\n",
    "    *[\"X\", \"Y\"]\n",
    "]\n",
    "\n",
    "df_center = df_from_folder(\"data/impacts/center\", locations, columns)\n",
    "df_front = df_from_folder(\"data/impacts/front\", locations, columns)\n",
    "\n",
    "df = pd.concat([df_center, df_front], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bfd52d",
   "metadata": {},
   "source": [
    "### Split of last entries into test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88d2de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 0.25\n",
    "split_indx = int(test_split * len(df_center))\n",
    "\n",
    "train_center, test_center = df_center.iloc[0:split_indx], df_center.iloc[split_indx:]\n",
    "train_front, test_front = df_front.iloc[0:split_indx], df_front.iloc[split_indx:]\n",
    "\n",
    "df_train = pd.concat([train_center, train_front], ignore_index=True)\n",
    "df_test = pd.concat([test_center, test_front], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c4ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"./data/dataset_train.csv\", index=False)\n",
    "df_test.to_csv(\"./data/dataset_test.csv\", index=False)\n",
    "df.to_csv(\"./data/dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
